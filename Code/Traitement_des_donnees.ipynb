{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traitement_des_donnees.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX0dySgqKLW"
      },
      "source": [
        "# Chapitre 3: Traitement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmL3JgwMbm7Q"
      },
      "source": [
        " \n",
        "## Changement des types de variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIJkeTJbm7Q"
      },
      "source": [
        "alltrain.timestamp=pd.to_datetime(alltrain['timestamp']) #Transformer la variable timestamp en format datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LczASt-Xbm7R"
      },
      "source": [
        "varia=['building_id','site_id', 'meter']\n",
        "\n",
        "for col in varia:\n",
        "    \n",
        "    alltrain[col]=alltrain[col].astype('object')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT_6Jovybm7S",
        "outputId": "fd69f8bc-94a3-4aed-e300-d44f49ccb8c0"
      },
      "source": [
        "alltrain.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20216100 entries, 0 to 20216099\n",
            "Data columns (total 16 columns):\n",
            " #   Column              Dtype         \n",
            "---  ------              -----         \n",
            " 0   building_id         object        \n",
            " 1   meter               object        \n",
            " 2   timestamp           datetime64[ns]\n",
            " 3   meter_reading       float64       \n",
            " 4   site_id             object        \n",
            " 5   primary_use         object        \n",
            " 6   square_feet         int64         \n",
            " 7   year_built          float64       \n",
            " 8   floor_count         float64       \n",
            " 9   air_temperature     float64       \n",
            " 10  cloud_coverage      float64       \n",
            " 11  dew_temperature     float64       \n",
            " 12  precip_depth_1_hr   float64       \n",
            " 13  sea_level_pressure  float64       \n",
            " 14  wind_direction      float64       \n",
            " 15  wind_speed          float64       \n",
            "dtypes: datetime64[ns](1), float64(10), int64(1), object(4)\n",
            "memory usage: 2.6+ GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLZxJobjbm7S"
      },
      "source": [
        "alltrain['meter'] = pd.Categorical(alltrain['meter']).rename_categories({0: 'electricity', \n",
        "                                                                   1: 'chilledwater',\n",
        "                                                                   2: 'steam', \n",
        "                                                                   3: 'hotwater'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptlkvNDNbm7T"
      },
      "source": [
        "## Occurence des modalités de chaque variable quali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm007q--bm7V",
        "outputId": "eb6f0180-0cb0-412d-d9c4-ff64b584341a"
      },
      "source": [
        " for col in alltrain.select_dtypes(object).columns:\n",
        "    print (f'{col :-<30} {len(alltrain[col].value_counts())}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building_id------------------- 1449\n",
            "site_id----------------------- 16\n",
            "primary_use------------------- 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fReXnTrQbm7W"
      },
      "source": [
        "## Analyse des valeurs manquantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFT1blWbm7W"
      },
      "source": [
        "(alltrain.isna().sum()/alltrain.shape[0]).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9XqZGO-bm7X"
      },
      "source": [
        "alltrain.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtnUkILpcVdT"
      },
      "source": [
        "La variable **floor_count** compte près de 82.7% de valeurs manquantes et environ 40% des valeurs de la variable **year_built** sont renseignées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmPR2dqDbm7Y"
      },
      "source": [
        "## Extraction de features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTieg0duW1iw"
      },
      "source": [
        "La base de données **weather_train** contient des données dépendantes du temps. Nous allons à cette étape créer d'autres variables à partir de ces variables qui permettent de les résumer.\\\n",
        "La fonction **preProcecing_df** permet de les réaliser en transformant par exemple les heures relevées et les dates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV7Mz8iEbm7Y"
      },
      "source": [
        "def rec_heur(x):\n",
        "    \n",
        "    if x in np.arange(6, 19):\n",
        "        return 'journee'\n",
        "    \n",
        "    if x in np.arange(19, 23):\n",
        "        return 'nuit'\n",
        "    \n",
        "    if x in [23, 0, 1, 2, 3, 4, 5]:\n",
        "        return 'tard'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NASxo80bm7c"
      },
      "source": [
        "def discredit_var(x):\n",
        "   \n",
        "    \n",
        "    if x <= 1951:\n",
        "        return 'yearB_q1'\n",
        "    \n",
        "    if  1951 < x <= 1969:\n",
        "        return 'yearB_q2'\n",
        "    \n",
        "    if 1969 < x <= 1993:\n",
        "        return 'yearB_q3'\n",
        "    \n",
        "    if  1993 < x:\n",
        "        return 'yearB_q4'\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5BwZEVPbm7n"
      },
      "source": [
        "def preProcecing_df(df_):\n",
        "    \n",
        "    df=df_.copy()\n",
        "    reduce_mem_usage(df)\n",
        "    \n",
        "    \n",
        "    saison={3: 'printent',4:'printent',5:'printent',\n",
        "          6: 'ete', 7: 'ete',8: 'ete', \n",
        "          9: 'automne', 10: 'automne', 11: 'automne', \n",
        "          1: 'hiver', 12: 'hiver', 2: 'hiver'}\n",
        "      \n",
        "    \n",
        "    df['mois'] = df.timestamp.dt.month\n",
        "    df['day'] = df.timestamp.dt.day\n",
        "    df['heure'] = df.timestamp.dt.hour\n",
        "    reduce_mem_usage(df)\n",
        "    \n",
        "    df['heureDiscredite'] = df['heure'].apply(rec_heur)\n",
        "    reduce_mem_usage(df)\n",
        "    \n",
        "    df['week_end'] = [1 if x in [5,6] else 0 for x in df.day]\n",
        "    reduce_mem_usage(df)\n",
        "    df['saison'] = df['mois'].apply(lambda x: saison.get(x))\n",
        "    reduce_mem_usage(df)\n",
        "    median_group = df.groupby(['site_id'])['year_built'].transform('median')\n",
        "    reduce_mem_usage(df)\n",
        "    df['year_built'].fillna(median_group,inplace = True)\n",
        "    reduce_mem_usage(df)\n",
        "    df['year_built'].fillna(df['year_built'].median(), inplace=True)\n",
        "    reduce_mem_usage(df)\n",
        "    df['year_built'] = df['year_built'].apply(discredit_var) \n",
        "    reduce_mem_usage(df)\n",
        "    df.floor_count.fillna(0,inplace = True)\n",
        "    reduce_mem_usage(df)\n",
        "    colonneAsNum=['air_temperature', 'dew_temperature','wind_direction']\n",
        "    for col in colonneAsNum:\n",
        "        median_group = df.groupby(['site_id', 'saison', 'week_end', 'primary_use'])[col].transform('median')\n",
        "        df[col].fillna(median_group,inplace = True)\n",
        "    reduce_mem_usage(df)                     \n",
        "    for col in [ 'day', 'heure', 'timestamp', \n",
        "                \"precip_depth_1_hr\", \"wind_speed\", \"sea_level_pressure\", \"cloud_coverage\", \"mois\"]:\n",
        "        del df[col]\n",
        "    reduce_mem_usage(df)\n",
        "    \n",
        "    return df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAuAbt7xbm7p"
      },
      "source": [
        "X = preProcecing_df(alltrain)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aHOgWVmUNOz"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYXfWqfU_FC"
      },
      "source": [
        "X1=X.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE5w7-owWmhJ"
      },
      "source": [
        "reduce_mem_usage(X1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMMJ777-YAoZ"
      },
      "source": [
        "Il est précisé que les valeurs de **meter_reading** enregistrées pour l'électricité et sur les bâtiments du site 0 sont en KBTU, unité différente des autres meter_reading enregistrées. Il faut pour cela procéder en la conversion de ces valeurs en les multipliant par 0.2931. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmsAMnelVX-c"
      },
      "source": [
        "X1.loc[  (X1.site_id==0)&(X1.meter == 'electricity') , 'meter_reading'] = X1.loc[(X1.site_id==0) & (X1.meter == 'electricity') , 'meter_reading'] * 0.2931"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aofbd4JQUI-2"
      },
      "source": [
        "X =  X[X['meter_reading']!= np.float(0)]\n",
        "X['meter_reading']=np.log1p(X['meter_reading'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX9NYhq-bm7p"
      },
      "source": [
        "(X.isna().sum()/X.shape[0]).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS3WVfkNS7_x"
      },
      "source": [
        "#X.to_csv (r'/content/X.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jLRw0eQbm7r"
      },
      "source": [
        "## conversion type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jd3_uY6bm7s"
      },
      "source": [
        "X[\"building_id\"] = X[\"building_id\"].astype('category')\n",
        "X[\"site_id\"] = X[\"site_id\"].astype('category')\n",
        "X[\"primary_use\"] = X[\"primary_use\"].astype('category')\n",
        "X[\"saison\"] = X[\"saison\"].astype('category')\n",
        "X[\"heureDiscredite\"] = X[\"heureDiscredite\"].astype('category')\n",
        "X[\"year_built\"] = X[\"year_built\"].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjgUIzCKbm7t"
      },
      "source": [
        "## Encodeur One Hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOWd9HmCYplP"
      },
      "source": [
        "Le programme ci-dessous permets d'encoder les variables. Nous avons choisi de créer de nouvelles variables en utilisant chaque modalité de la variable cible comme nouvelle variable.\\\n",
        "Ainsi, si par exemple une variable compte 7 variables, le programme **encodeur** permettra d'obtenir 7 autres variables avec **Oui: 1** si la modalité est présente dans la variable de départ et **Non: 0** sinon. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjvZb5F0bm7u"
      },
      "source": [
        "def encodeur(df): \n",
        "    X_Encod=pd.concat([df, pd.get_dummies(df[\"primary_use\"], dtype=int) ], axis=1)\n",
        "    reduce_mem_usage(df)\n",
        "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"saison\"], dtype=int) ], axis=1)\n",
        "    reduce_mem_usage(df)\n",
        "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"heureDiscredite\"], dtype=int) ], axis=1)\n",
        "    reduce_mem_usage(df)\n",
        "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"meter\"], dtype=int) ], axis=1)\n",
        "    reduce_mem_usage(df)\n",
        "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"year_built\"], dtype=int) ], axis=1)\n",
        "    reduce_mem_usage(df)\n",
        "\n",
        "    for col in [\"primary_use\",'year_built', 'yearB_q4', \"saison\", \"heureDiscredite\", \n",
        "                'Office', \"printent\", \"journee\", 'meter', 'hotwater' ]:\n",
        "        del X_Encod[col]\n",
        "\n",
        "\n",
        "    return X_Encod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNB-9qicicl2"
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwVfcd3UVnZF"
      },
      "source": [
        "X_Encod.to_csv (r'/content/drive/MyDrive/Kaggle/X_Encod.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRJqSo_3bm7v"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZP5uDhQZ1uH"
      },
      "source": [
        "Dans cette partie, nous allons diviser la base en ensemble d'apprentissage et d'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTKSQXU2bm7w"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "def trainAndTest(DF):\n",
        "    df= DF.copy()\n",
        "    \n",
        "    uniqueSite=list(pd.unique(df[\"site_id\"]))\n",
        "    rs = ShuffleSplit(n_splits=1, test_size=.3, random_state=0)\n",
        "    for train_index, test_index in rs.split(uniqueSite):\n",
        "\n",
        "        df['trainIndex'] = [1 if x in train_index else 0 for x in df.site_id]\n",
        "        x_train = df[df['trainIndex']==1]\n",
        "        y_train = x_train['meter_reading']\n",
        "\n",
        "        x_test = df[df['trainIndex']==0]\n",
        "        y_test = x_test['meter_reading']\n",
        "\n",
        "    del x_train['trainIndex'] \n",
        "    del x_train['meter_reading'] \n",
        "\n",
        "    del x_test['trainIndex']\n",
        "    del x_test['meter_reading']\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWQink3Mbm7x"
      },
      "source": [
        " X_train, Y_train, X_test, Y_test = trainAndTest(X_Encod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwQ_SbVWtO1"
      },
      "source": [
        "X_train=reduce_mem_usage(X_train)\n",
        "X_test=reduce_mem_usage(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHqOzXe1bm7x"
      },
      "source": [
        "## MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSWNI8k2bm72"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Nu4TNobm73"
      },
      "source": [
        "def minMax(DF, listColumns, scaler):\n",
        "    df=DF.copy()\n",
        "    for col in listColumns:\n",
        "        df[col]=scaler.fit_transform(df[[col]])\n",
        "    reduce_mem_usage(df)  \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn6U791Nbm73"
      },
      "source": [
        "listColumns= [ 'wind_direction',  'dew_temperature',\n",
        "              'air_temperature', 'floor_count', 'square_feet']\n",
        "\n",
        "\n",
        "X_train = minMax(X_train, listColumns, scaler)\n",
        "X_test = minMax(X_test, listColumns, scaler)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}