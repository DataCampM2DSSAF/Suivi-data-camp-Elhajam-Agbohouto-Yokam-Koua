{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data camp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "weather_train = pd.read_csv('weather_train.csv')\n",
    "weather_test = pd.read_csv('weather_test.csv')\n",
    "building_metadata = pd.read_csv('building_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(building_metadata, on='building_id', how='left')\n",
    "alltrain = train.merge(weather_train, on=['site_id','timestamp'], how='left')\n",
    "#del building_metadata,weather_train,train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltrain.timestamp = pd.to_datetime(alltrain['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varia = ['building_id','site_id', 'meter']\n",
    "\n",
    "for col in varia:\n",
    "    \n",
    "    alltrain[col] =alltrain[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltrain['meter'] = pd.Categorical(alltrain['meter']).rename_categories({0: 'electricity', \n",
    "                                                                   1: 'chilledwater',\n",
    "                                                                   2: 'steam', \n",
    "                                                                   3: 'hotwater'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rec_heur(x):\n",
    "    \n",
    "    if x in np.arange(6, 19):\n",
    "        return 'journee'\n",
    "    \n",
    "    if x in np.arange(19, 23):\n",
    "        return 'nuit'\n",
    "    \n",
    "    if x in [23, 0, 1, 2, 3, 4, 5]:\n",
    "        return 'tard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discredit_var(x):\n",
    "   \n",
    "    \n",
    "    if x <= 1951:\n",
    "        return 'yearB_q1'\n",
    "    \n",
    "    if  1951 < x <= 1969:\n",
    "        return 'yearB_q2'\n",
    "    \n",
    "    if 1969 < x <= 1993:\n",
    "        return 'yearB_q3'\n",
    "    \n",
    "    if  1993 < x:\n",
    "        return 'yearB_q4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcecing_df(df_):\n",
    "    \n",
    "    df=df_.copy()\n",
    "    reduce_mem_usage(df)\n",
    "    \n",
    "    \n",
    "    saison={3: 'printent',4:'printent',5:'printent',\n",
    "          6: 'ete', 7: 'ete',8: 'ete', \n",
    "          9: 'automne', 10: 'automne', 11: 'automne', \n",
    "          1: 'hiver', 12: 'hiver', 2: 'hiver'}\n",
    "      \n",
    "    \n",
    "    df['mois'] = df.timestamp.dt.month\n",
    "    df['day'] = df.timestamp.dt.day\n",
    "    df['heure'] = df.timestamp.dt.hour\n",
    "    reduce_mem_usage(df)\n",
    "    \n",
    "    df['heureDiscredite'] = df['heure'].apply(rec_heur)\n",
    "    reduce_mem_usage(df)\n",
    "    \n",
    "    df['week_end'] = [1 if x in [5,6] else 0 for x in df.day]\n",
    "    reduce_mem_usage(df)\n",
    "    df['saison'] = df['mois'].apply(lambda x: saison.get(x))\n",
    "    reduce_mem_usage(df)\n",
    "    median_group = df.groupby(['site_id'])['year_built'].transform('median')\n",
    "    reduce_mem_usage(df)\n",
    "    df['year_built'].fillna(median_group,inplace = True)\n",
    "    reduce_mem_usage(df)\n",
    "    df['year_built'].fillna(df['year_built'].median(), inplace=True)\n",
    "    reduce_mem_usage(df)\n",
    "    df['year_built'] = df['year_built'].apply(discredit_var) \n",
    "    reduce_mem_usage(df)\n",
    "    df.floor_count.fillna(0,inplace = True)\n",
    "    reduce_mem_usage(df)\n",
    "    colonneAsNum=['air_temperature', 'dew_temperature','wind_direction']\n",
    "    for col in colonneAsNum:\n",
    "        median_group = df.groupby(['site_id', 'saison', 'week_end', 'primary_use'])[col].transform('median')\n",
    "        df[col].fillna(median_group,inplace = True)\n",
    "    reduce_mem_usage(df)                     \n",
    "    for col in [ 'day', 'heure', 'timestamp', \n",
    "                \"precip_depth_1_hr\", \"wind_speed\", \"sea_level_pressure\", \"cloud_coverage\", \"mois\"]:\n",
    "        del df[col]\n",
    "    reduce_mem_usage(df)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1291.73 MB\n",
      "Decreased by 48.1%\n",
      "Memory usage after optimization is: 1349.57 MB\n",
      "Decreased by 23.1%\n",
      "Memory usage after optimization is: 1503.81 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1523.09 MB\n",
      "Decreased by 8.1%\n",
      "Memory usage after optimization is: 1677.32 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1677.32 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1677.32 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1677.32 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1793.00 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1793.00 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1793.00 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1426.69 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "X = preProcecing_df(alltrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1426.69 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "X = reduce_mem_usage(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"building_id\"] = X[\"building_id\"].astype('category')\n",
    "X[\"site_id\"] = X[\"site_id\"].astype('category')\n",
    "X[\"primary_use\"] = X[\"primary_use\"].astype('category')\n",
    "X[\"saison\"] = X[\"saison\"].astype('category')\n",
    "X[\"heureDiscredite\"] = X[\"heureDiscredite\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.loc[  (X.site_id==0)&(X.meter == 'electricity') , 'meter_reading'] = X.loc[(X.site_id==0) & (X.meter == 'electricity') , 'meter_reading'] * 0.2931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X =  X[X['meter_reading']!= np.float(0)]\n",
    "X['meter_reading']=np.log1p(X['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18342124, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 14 colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeur(df): \n",
    "    X_Encod=pd.concat([df, pd.get_dummies(df[\"primary_use\"]) ], axis=1)\n",
    "    reduce_mem_usage(X_Encod)\n",
    "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"saison\"]) ], axis=1)\n",
    "    reduce_mem_usage(X_Encod)\n",
    "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"heureDiscredite\"]) ], axis=1)\n",
    "    reduce_mem_usage(X_Encod)\n",
    "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"meter\"]) ], axis=1)\n",
    "    reduce_mem_usage(X_Encod)\n",
    "    X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"year_built\"]) ], axis=1)\n",
    "    reduce_mem_usage(X_Encod)\n",
    "\n",
    "    for col in [\"primary_use\",'year_built', \"saison\", \"heureDiscredite\", 'meter']:\n",
    "        del X_Encod[col]\n",
    "\n",
    "\n",
    "    return X_Encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 944.64 MB\n",
      "Decreased by 3.6%\n",
      "Memory usage after optimization is: 1014.61 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1067.09 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1137.06 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 1207.03 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "X_Encod = encodeur(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18342124, 40)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Encod.shape # 40 colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_Encod['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18342124, 39)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Encod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def trainAndTest(DF):\n",
    "    df= DF.copy()\n",
    "    \n",
    "    uniqueSite=list(pd.unique(df[\"site_id\"]))\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=.3, random_state=0)\n",
    "    for train_index, test_index in rs.split(uniqueSite):\n",
    "\n",
    "        df['trainIndex'] = [1 if x in train_index else 0 for x in df.site_id]\n",
    "        x_train = df[df['trainIndex']==1]\n",
    "        y_train = x_train['meter_reading']\n",
    "\n",
    "        x_test = df[df['trainIndex']==0]\n",
    "        y_test = x_test['meter_reading']\n",
    "\n",
    "    del x_train['trainIndex'] \n",
    "    del x_train['meter_reading'] \n",
    "\n",
    "    del x_test['trainIndex']\n",
    "    del x_test['meter_reading']\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " X_train, Y_train, X_test, Y_test = trainAndTest(X_Encod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMax(DF, listColumns, scaler):\n",
    "    df=DF.copy()\n",
    "    for col in listColumns:\n",
    "        df[col]=scaler.fit_transform(df[[col]])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listColumns= [ 'wind_direction',  'dew_temperature',\n",
    "              'air_temperature', 'floor_count', 'square_feet']\n",
    "\n",
    "\n",
    "X_train = minMax(X_train, listColumns, scaler)\n",
    "X_test = minMax(X_test, listColumns, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 576.20 MB\n",
      "Decreased by 37.0%\n",
      "Memory usage after optimization is: 315.92 MB\n",
      "Decreased by 37.0%\n"
     ]
    }
   ],
   "source": [
    "X_train =reduce_mem_usage(X_train)\n",
    "X_test =reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_csv ('x_train.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.to_csv ('x_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test.to_csv ('y_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train.to_csv ('y_train.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(min_samples_split=200,min_samples_leaf=150)\n",
    "dtr = dtr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.70312156781\n"
     ]
    }
   ],
   "source": [
    " from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "y_pred_dtr = dtr.predict(X_test)\n",
    "print(mean_squared_error(Y_test, y_pred_dtr)** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "br = BaggingRegressor(random_state=0)\n",
    "br = br.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred_br = br.predict(X_test)\n",
    "print(mean_squared_error(Y_test, y_pred_br)** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.merge(building_metadata, on='building_id', how='left')\n",
    "alltest = test.merge(weather_test, on=['site_id','timestamp'], how='left')\n",
    "#del building_metadata,weather_train,train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltest.timestamp = pd.to_datetime(alltest['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alltest['meter'] = pd.Categorical(alltest['meter']).rename_categories({0: 'electricity', \n",
    "                                                                   1: 'chilledwater',\n",
    "                                                                   2: 'steam', \n",
    "                                                                   3: 'hotwater'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 2147.36 MB\n",
      "Decreased by 58.1%\n",
      "Memory usage after optimization is: 2266.66 MB\n",
      "Decreased by 26.9%\n",
      "Memory usage after optimization is: 2584.79 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2624.55 MB\n",
      "Decreased by 9.6%\n",
      "Memory usage after optimization is: 2942.68 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2942.68 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2942.68 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2942.68 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 3181.27 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 3181.27 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 3181.27 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2425.72 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "data_test = preProcecing_df(alltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test[\"building_id\"] = data_test[\"building_id\"].astype('category')\n",
    "data_test[\"site_id\"] = data_test[\"site_id\"].astype('category')\n",
    "data_test[\"primary_use\"] = data_test[\"primary_use\"].astype('category')\n",
    "data_test[\"saison\"] = data_test[\"saison\"].astype('category')\n",
    "data_test[\"heureDiscredite\"] = data_test[\"heureDiscredite\"].astype('category')\n",
    "data_test[\"year_built\"] = data_test[\"year_built\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listColumns= [ 'wind_direction',  'dew_temperature',\n",
    "              'air_temperature', 'floor_count', 'square_feet']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 1948.58 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2107.65 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2226.94 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2386.01 MB\n",
      "Decreased by 0.0%\n",
      "Memory usage after optimization is: 2545.07 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "X_final = encodeur(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minMax(DF, listColumns, scaler):\n",
    "    df=DF.copy()\n",
    "    for col in listColumns:\n",
    "        df[col]=scaler.fit_transform(df[[col]])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_final = minMax(X_final, listColumns, scaler)\n",
    "del data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_final = X_final.drop([\"row_id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('x_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(min_samples_split=200,min_samples_leaf=150)\n",
    "dtr = dtr.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_final = dtr.predict(X_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypred_finaldf = pd.DataFrame(data=y_pred_final)\n",
    "Ypred_finaldf.to_csv('mypred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission  = pd.read_csv('sample_submission.csv')\n",
    "submission['meter_reading'] = np.exp(y_pred_final)\n",
    "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
    "submission.to_csv('mysubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br = BaggingRegressor(random_state=0)\n",
    "br = br.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_final2 = br.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypred_finaldf2 = pd.DataFrame(data=y_pred_final2)\n",
    "Ypred_finaldf2.to_csv('mypred2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2  = pd.read_csv('sample_submission.csv')\n",
    "submission2['meter_reading'] = np.exp(y_pred_final2)\n",
    "submission2.loc[submission2['meter_reading']<0, 'meter_reading'] = 0\n",
    "submission2.to_csv('mysubmission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
