{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Projet_data camp_modeles 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-bYUWjORZqV"
      },
      "source": [
        "## ASHRAE Energy Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyVeGa-CT28d"
      },
      "source": [
        "## Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9WUFQs3HVuX",
        "outputId": "9d6fba47-7f85-471e-eab1-590b31518fca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERqdtTv9RZqY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import scipy.stats\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "le = LabelEncoder()\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "from sklearn.ensemble import IsolationForest\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GMYzw1ERZqa"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/train.csv')\n",
        "weather_train = pd.read_csv('drive/MyDrive/weather_train.csv')\n",
        "building_metadata = pd.read_csv('drive/MyDrive/building_metadata.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCVuxLMgVrKu"
      },
      "source": [
        "# Fusion des différentes tables de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKiNrDaCV4ZS",
        "outputId": "428069b5-8b98-45e4-d05b-bb06710bdb7b"
      },
      "source": [
        "train = train.merge(building_metadata, on='building_id', how='left')\n",
        "train.loc[  (train.site_id==0)&(train.meter == 'electricity') , 'meter_reading'] *= 0.2931\n",
        "alltrain = train.merge(weather_train, on=['site_id','timestamp'], how='left')\n",
        "del building_metadata,weather_train,train\n",
        "gc.collect()\n",
        "print(alltrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20216100, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eEUtRO5WBBr"
      },
      "source": [
        "La base de données complète contient au total ... individus et ... variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HDpk1ivLMb2"
      },
      "source": [
        "**mauvaise compréhension des variables: building_id, timestamp, site_id et meter**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdBy73hpLMb7"
      },
      "source": [
        "## Analyse des valeurs manquantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyXnVA09LMb8",
        "outputId": "f3115cb0-3fe4-4a0b-8de5-7d742226dd3d"
      },
      "source": [
        "(alltrain.isna().sum()/alltrain.shape[0]).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "floor_count           0.826528\n",
              "year_built            0.599900\n",
              "cloud_coverage        0.436551\n",
              "precip_depth_1_hr     0.185447\n",
              "wind_direction        0.071678\n",
              "sea_level_pressure    0.060925\n",
              "wind_speed            0.007107\n",
              "dew_temperature       0.004953\n",
              "air_temperature       0.004781\n",
              "square_feet           0.000000\n",
              "primary_use           0.000000\n",
              "site_id               0.000000\n",
              "meter_reading         0.000000\n",
              "timestamp             0.000000\n",
              "meter                 0.000000\n",
              "building_id           0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Gbk0xVZZLMb-",
        "outputId": "c378bba2-53eb-4ea8-9d01-e8be182864d4"
      },
      "source": [
        "alltrain.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>meter_reading</th>\n",
              "      <th>site_id</th>\n",
              "      <th>primary_use</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>air_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>dew_temperature</th>\n",
              "      <th>precip_depth_1_hr</th>\n",
              "      <th>sea_level_pressure</th>\n",
              "      <th>wind_direction</th>\n",
              "      <th>wind_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>2720</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>5376</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>23685</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>116607</td>\n",
              "      <td>1975.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1019.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   building_id  meter  ... wind_direction  wind_speed\n",
              "0            0      0  ...            0.0         0.0\n",
              "1            1      0  ...            0.0         0.0\n",
              "2            2      0  ...            0.0         0.0\n",
              "3            3      0  ...            0.0         0.0\n",
              "4            4      0  ...            0.0         0.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu6IR-nlLMb_"
      },
      "source": [
        "## Extraction de features et pré-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzvZBXe-LMb_"
      },
      "source": [
        "def rec_heur(x):\n",
        "  \"\"\"Cette fonction, regroupera les heures de la journée en 3 grands groupes, donc elle permettra de créer \n",
        "  une nouvelle variable qu'on appeler plus tard heureDiscredite\"\"\"\n",
        "    \n",
        "  if x in np.arange(6, 19):\n",
        "        return 'journee'\n",
        "    \n",
        "  if x in np.arange(19, 23):\n",
        "        return 'nuit'\n",
        "    \n",
        "  if x in [23, 0, 1, 2, 3, 4, 5]:\n",
        "        return 'tard'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8F7TiuRLMcB"
      },
      "source": [
        "def discredit_var(x):\n",
        "\n",
        "  \"\"\"De même pour cette fonction, regroupera les ages des batiments suivant les quantiles\n",
        "    Q1= 1951 , Q2= 1969, Q3 = 1993, donc elle permettra de recoder la variable year_built\"\"\"\n",
        "    \n",
        "  if x <= 1951:\n",
        "      return 'yearB_q1'\n",
        "    \n",
        "  if  1951 < x <= 1969:\n",
        "      return 'yearB_q2'\n",
        "    \n",
        "  if 1969 < x <= 1993:\n",
        "      return 'yearB_q3'\n",
        "    \n",
        "  if  1993 < x:\n",
        "      return 'yearB_q4'\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27KHcQ8s_xWm"
      },
      "source": [
        "def preProcecing_df(df_):\n",
        "    \"\"\"La fonction preProcecing, suit ces étapes:\n",
        "    - Transformation de la variable timestamp en datetime et renomme les modalités de meter\n",
        "    - Création des variables heureDiscredite, week_end et saison \n",
        "    - Remplissage des valeurs NAN:\n",
        "\n",
        "          * Un groupby suivant site_id et year_built puis calcul la médianne de chaque groupe afin \n",
        "            de remplir certaines valeurs manquantes de year_built, et recode la variable year_built, \n",
        "            enfin, les autres valeurs manquantes seront remplies par le mode de  year_built recodé.\n",
        "\n",
        "          * Un groupby suivant les variables 'site_id', 'saison', 'week_end' et 'primary_use'\n",
        "          puis calcul la médianne de chaque groupe afin de remplir certaines valeurs manquantes,\n",
        "          enfin, les autres valeurs manquantes seront remplies par la médianne\n",
        "\n",
        "          * Quant à la variable floor_count, ces valeurs manquantes seront remplacées par 0.\n",
        "\n",
        "    - Conversion des variables dont le type à été mal compris. \n",
        "    - Suppression des variables inutiles.\"\"\"\n",
        "\n",
        "    df=df_.copy()\n",
        "    \n",
        "    \n",
        "    saison={3: 'printent',4:'printent',5:'printent',\n",
        "          6: 'ete', 7: 'ete',8: 'ete', \n",
        "          9: 'automne', 10: 'automne', 11: 'automne', \n",
        "          1: 'hiver', 12: 'hiver', 2: 'hiver'}\n",
        "      \n",
        "    df.timestamp=pd.to_datetime(df['timestamp'])\n",
        "\n",
        "    df['meter'] = pd.Categorical(df['meter']).rename_categories({0: 'electricity', \n",
        "                                                                   1: 'chilledwater',\n",
        "                                                                   2: 'steam', \n",
        "                                                                   3: 'hotwater'})\n",
        "\n",
        "    df['mois'] = df.timestamp.dt.month\n",
        "    df['day'] = df.timestamp.dt.day\n",
        "    df['heure'] = df.timestamp.dt.hour\n",
        "    \n",
        "    df['heureDiscredite'] = df['heure'].apply(rec_heur)\n",
        "    \n",
        "    df['week_end'] = [1 if x in [5,6] else 0 for x in df.day]\n",
        "\n",
        "    df['saison'] = df['mois'].apply(lambda x: saison.get(x))\n",
        "\n",
        "    median_group = df.groupby(['site_id'])['year_built'].transform('median')\n",
        "\n",
        "    df['year_built'].fillna(median_group,inplace = True)\n",
        "\n",
        "    df['year_built'].fillna(df['year_built'].median(), inplace=True)\n",
        "\n",
        "    df['year_built'] = df['year_built'].apply(discredit_var) \n",
        "\n",
        "    df.floor_count.fillna(0,inplace = True)\n",
        "    df['square_feet']=np.log(df['square_feet'])\n",
        "\n",
        "    colonneAsNum=['air_temperature', 'dew_temperature','wind_direction']\n",
        "\n",
        "    for col in colonneAsNum:\n",
        "        median_group = df.groupby(['site_id', 'saison', 'week_end', 'primary_use'])[col].transform('median')\n",
        "        df[col].fillna(median_group,inplace = True)\n",
        "\n",
        "    for col in [ 'day', 'heure', 'timestamp',  \"precip_depth_1_hr\", \"wind_speed\", \n",
        "                \"sea_level_pressure\", \"cloud_coverage\", \"mois\"]:\n",
        "        del df[col]\n",
        "\n",
        "    \n",
        "    df[\"building_id\"] = df[\"building_id\"].astype('category')\n",
        "    df[\"site_id\"] = df[\"site_id\"].astype('category')\n",
        "    df[\"saison\"] = df[\"saison\"].astype('category')\n",
        "    df[\"heureDiscredite\"] = df[\"heureDiscredite\"].astype('category')\n",
        "    df[\"year_built\"] = df[\"year_built\"].astype('category')\n",
        "    df[\"primary_use\"] = df[\"primary_use\"].astype('category')\n",
        "\n",
        "    if 'meter_reading' in df.columns:\n",
        "      df =  df[df['meter_reading']!= np.float(0)]\n",
        "      df['meter_reading']=np.log1p(df['meter_reading'])\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    return df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2FKbUMLMcG"
      },
      "source": [
        "## Encodeur One Hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGKyxCWhAQn3"
      },
      "source": [
        "def encodeur(df): \n",
        "\n",
        "  \"\"\"Cette fonction rajoutera comme nouvelle variable les n-1 modalités de chaque variable\n",
        "   qualitative   puis la supprimera.\n",
        "  \"\"\"\n",
        "  \n",
        "  X_Encod=pd.concat([df, pd.get_dummies(df[\"primary_use\"], dtype=int) ], axis=1)\n",
        "\n",
        "  X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"saison\"], dtype=int) ], axis=1)\n",
        "\n",
        "  X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"heureDiscredite\"], dtype=int) ], axis=1)\n",
        "  X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"meter\"], dtype=int) ], axis=1)\n",
        "  X_Encod=pd.concat([X_Encod, pd.get_dummies(df[\"year_built\"], dtype=int) ], axis=1)\n",
        "\n",
        "  for col in ['year_built', 'yearB_q4', \"saison\",\"printent\",\n",
        "                \"heureDiscredite\", \"journee\", 'meter', 'hotwater','Office',\"primary_use\" ]:\n",
        "      del X_Encod[col]\n",
        "\n",
        "\n",
        "  return X_Encod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waE-Dn69LMcH"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfTCKXBAWZU"
      },
      "source": [
        "def trainAndTest(DF):\n",
        "    df= DF.copy()\n",
        "    \n",
        "    uniqueSite=list(pd.unique(df[\"site_id\"]))\n",
        "    rs = ShuffleSplit(n_splits=1, test_size=.7, random_state=0)\n",
        "    for train_index, test_index in rs.split(uniqueSite):\n",
        "\n",
        "        df['trainIndex'] = [1 if x in train_index else 0 for x in df.site_id]\n",
        "        x_train = df[df['trainIndex']==1]\n",
        "        y_train = x_train['meter_reading']\n",
        "\n",
        "        x_test = df[df['trainIndex']==0]\n",
        "        y_test = x_test['meter_reading']\n",
        "\n",
        "    del x_train['trainIndex'] \n",
        "    del x_train['meter_reading'] \n",
        "\n",
        "    del x_test['trainIndex']\n",
        "    del x_test['meter_reading']\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggmDoIt9Khg-"
      },
      "source": [
        "# *Standadisartion*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flj1m_eNAvV4"
      },
      "source": [
        "def minMax(DF, listColumns, scaler):\n",
        "    df=DF.copy()\n",
        "    for col in listColumns:\n",
        "        df[col]=scaler.fit_transform(df[[col]])\n",
        "        \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdgYUOHnQ6zs"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzwy1smmOGwo"
      },
      "source": [
        "listColumns= [ 'wind_direction',  'dew_temperature',\n",
        "              'air_temperature', 'floor_count', 'square_feet']\n",
        "def my_pipe(df, trainTest= True):\n",
        "\n",
        "  X = preProcecing_df(df)\n",
        "\n",
        "  X = encodeur(X)\n",
        "\n",
        "  if trainTest:\n",
        "    X_train, Y_train, X_test, Y_test = trainAndTest(X)\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "  \n",
        "  X_final = minMax( X, listColumns, scaler)\n",
        "\n",
        "  return X_final.drop([\"row_id\"],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8clbNyPgKogj"
      },
      "source": [
        "# Retrait des valeurs aberrantes en utilisant IsolationForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AFDjSNroPMR"
      },
      "source": [
        "x_train, Y_train, X_test, Y_test = my_pipe(alltrain)\n",
        "clf = IsolationForest(random_state=0).fit(x_train)\n",
        "y_ab = clf.predict(x_train)\n",
        "x_train = x_train[y_ab==1]\n",
        "y_train = Y_train[y_ab==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1s8-r-ZWEfd"
      },
      "source": [
        "X_test=minMax( X_test, listColumns, scaler)\n",
        "x_train=minMax( x_train, listColumns, scaler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iboLl2daLAbY"
      },
      "source": [
        "# Entrainement  et Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwGBpb2UBHYN"
      },
      "source": [
        "def modelTrain(x_train, y_train, x_test, y_test, modEl):\n",
        "    \n",
        "    modEl.fit(x_train, y_train)\n",
        "    \n",
        "    y_pred = modEl.predict(x_test)\n",
        "    scOre = np.sqrt(mean_squared_error(y_test, y_pred) )\n",
        "    \n",
        "    return scOre, modEl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dajntvdNXPo3"
      },
      "source": [
        "\n",
        "## GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jeCaZMtXAoO"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbr = GradientBoostingRegressor(random_state=0, \n",
        "                                    learning_rate= 0.05,\n",
        "                                   n_estimators = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaDRvKTeHWef"
      },
      "source": [
        "\n",
        "scOre, gbr = modelTrain(x_train, y_train, X_test, Y_test, gbr)\n",
        "pickle.dump(Gbr, open(\"drive/MyDrive/gbr.pickle.dat\", \"wb\"))\n",
        "scOre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7socrH9R77g"
      },
      "source": [
        "pickle.dump(Gbr, open(\"drive/MyDrive/gbr.pickle.dat\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl9CqnchSZAE"
      },
      "source": [
        "pickle.dump(Gbr, open(\"drive/MyDrive/gbr.pickle.dat\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMl0OXcBX_9-"
      },
      "source": [
        "## HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1BHebbZX_HS"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "\n",
        "hgbr = HistGradientBoostingRegressor(random_state=0,\n",
        "                                     scoring='neg_root_mean_squared_error',\n",
        "                                     max_depth = 20 \n",
        "                                     )\n",
        "scOre_h, hgbr = modelTrain(x_train, y_train, X_test, Y_test, hgbr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YIu8brLYK21"
      },
      "source": [
        "# choix du modele"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdXsx-8HLMcL"
      },
      "source": [
        "## Soumission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Mv6H4rLMcM",
        "outputId": "6aedafa0-b654-40b3-a78b-a0124c155118"
      },
      "source": [
        "test = pd.read_csv('drive/MyDrive/test.csv')\n",
        "weather_test = pd.read_csv('drive/MyDrive/weather_test.csv')\n",
        "building_metadata = pd.read_csv('drive/MyDrive/building_metadata.csv')\n",
        "\n",
        "test =test.merge(building_metadata, on='building_id', how='left')\n",
        "alltest= test.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
        "del test, weather_test,building_metadata\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aoelKCFLMcO"
      },
      "source": [
        "X_final = my_pipe(alltest, trainTest= False) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYI-ivY8LMcO"
      },
      "source": [
        "loaded_model = pickle.load(open(\"pima.pickle.dat\", \"rb\"))\n",
        "y_pred_final = loaded_model.predict(X_final)\n",
        "y_pred_final.loc[ (X_final.site_id==0)&(X_final.electricity==1) ] /=0.2931\n",
        "Ypred_finaldf = pd.DataFrame(data=y_pred_final)\n",
        "Ypred_finaldf.to_csv('mypred.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZsh7cvyvFgu"
      },
      "source": [
        "submission  = pd.read_csv('drive/MyDrive/sample_submission.csv')\n",
        "submission['meter_reading'] = np.exp(y_pred_final)\n",
        "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
        "submission.to_csv('drive/MyDrive/mysubmission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}